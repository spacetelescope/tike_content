{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60a8d99f-e4b2-4346-b153-7848816dc522",
   "metadata": {},
   "source": [
    "# TIKE LTS Kernel Testing\n",
    "For the most part, I've tried to make it obvious where the packages are used by leaving the imports at the top of the cells.\n",
    "\n",
    "**Last updated: Nov 2023**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f5981e-b3ec-4398-a7ee-7a4c4ef59e25",
   "metadata": {},
   "source": [
    "## Astropy & Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be50547-303c-435b-b78d-dfdc98c84425",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from astropy.time import Time\n",
    "from astropy.io import fits\n",
    "from astropy.utils.data import get_pkg_data_filename\n",
    "from astropy.visualization import astropy_mpl_style\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use(astropy_mpl_style)\n",
    "\n",
    "# Check that we can set a time\n",
    "times = ['1999-01-01T00:00:00.123456789', '2010-01-01T00:00:00']\n",
    "t = Time(times, format='isot', scale='utc')\n",
    "\n",
    "# Get an image, print info\n",
    "image_file = get_pkg_data_filename('tutorials/FITS-images/HorseHead.fits')\n",
    "fits.info(image_file)\n",
    "\n",
    "# Get underlying data, print shape\n",
    "image_data = fits.getdata(image_file, ext=0)\n",
    "print(image_data.shape)\n",
    "\n",
    "# Actually make/plot the figure\n",
    "plt.figure()\n",
    "plt.imshow(image_data, cmap='gray')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f252756-e06f-4b5b-863f-6d114f311255",
   "metadata": {},
   "source": [
    "## Astroquery & Boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c705ea4f-0696-4553-85da-0fd17128fe0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "\n",
    "from astropy.io import fits\n",
    "from astroquery.mast import Observations\n",
    "\n",
    "Observations.enable_cloud_dataset()\n",
    "fs = s3fs.S3FileSystem(anon=True)\n",
    "\n",
    "obs = Observations.query_criteria(obs_collection=\"TESS\", target_name='219796019', sequence_number=57)\n",
    "if len(obs) == 0:\n",
    "    raise Exception(\"Team Octarine: Contact MAST. Invalid target criteria\")\n",
    "prod = Observations.get_product_list(obs)\n",
    "uris = Observations.get_cloud_uris(prod)\n",
    "\n",
    "with fs.open(uris[0]) as f:\n",
    "    fits.info(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34eceb0-cc29-4691-8671-132f3956a83a",
   "metadata": {},
   "source": [
    "## Batman\n",
    "Also tests numpy and matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993cd092-e084-4ee6-ba71-d80bd25dd2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import batman\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "params = batman.TransitParams()       #object to store transit parameters\n",
    "params.t0 = 0.                        #time of inferior conjunction\n",
    "params.per = 1.                       #orbital period\n",
    "params.rp = 0.1                       #planet radius (in units of stellar radii)\n",
    "params.a = 15.                        #semi-major axis (in units of stellar radii)\n",
    "params.inc = 87.                      #orbital inclination (in degrees)\n",
    "params.ecc = 0.                       #eccentricity\n",
    "params.w = 90.                        #longitude of periastron (in degrees)\n",
    "params.limb_dark = \"nonlinear\"        #limb darkening model\n",
    "params.u = [0.5, 0.1, 0.1, -0.1]      #limb darkening coefficients [u1, u2, u3, u4]\n",
    "\n",
    "t = np.linspace(-0.025, 0.025, 1000)  #times at which to calculate light curve\n",
    "m = batman.TransitModel(params, t)    #initializes model\n",
    "\n",
    "flux = m.light_curve(params)    \n",
    "radii = np.linspace(0.09, 0.11, 20)\n",
    "for r in radii:\n",
    "        params.rp = r                           #updates planet radius\n",
    "        new_flux = m.light_curve(params)        #recalculates light curve\n",
    "        plt.plot(t, new_flux)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38028c6b-a17e-48a1-a740-904bc5e466c1",
   "metadata": {},
   "source": [
    "## Bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0762198-213a-4946-8186-27686e62e08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import output_notebook\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "''' A color mapping plot with color spectrum scale. The example plots demonstrates\n",
    "log mapping and linear mapping with different color palette.\n",
    "\n",
    ".. bokeh-example-metadata::\n",
    "    :apis: bokeh.plotting.Figure.scatter, bokeh.models.ColumnDataSource, bokeh.models.annotations.ColorBar, bokeh.models.mappers.LinearColorMapper, bokeh.models.mappers.LogColorMapper\n",
    "    :refs: :ref:`ug_topics_images_colormapped`\n",
    "    :keywords: color, tools, scatter, data_map\n",
    "\n",
    "''' # noqa: E501\n",
    "import numpy as np\n",
    "\n",
    "from bokeh.layouts import column, gridplot\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.transform import linear_cmap, log_cmap\n",
    "\n",
    "x = np.random.random(size=2000) * 1000\n",
    "y = np.random.normal(size=2000) * 2 + 5\n",
    "source = ColumnDataSource(dict(x=x, y=y))\n",
    "\n",
    "def make_plot(mapper, palette):\n",
    "    cmap = mapper(\"x\", palette=palette, low=1, high=1000)\n",
    "    axis_type = mapper.__name__.split(\"_\")[0] # linear or log\n",
    "\n",
    "    p = figure(x_range=(1, 1000), title=f\"{palette} with {mapper.__name__}\",\n",
    "               toolbar_location=None, tools=\"\", x_axis_type=axis_type)\n",
    "\n",
    "    r = p.scatter('x', 'y', alpha=0.8, source=source, color=cmap)\n",
    "\n",
    "    color_bar = r.construct_color_bar(padding=0,\n",
    "                                      ticker=p.xaxis.ticker,\n",
    "                                      formatter=p.xaxis.formatter)\n",
    "    p.add_layout(color_bar, 'below')\n",
    "\n",
    "    return p\n",
    "\n",
    "p1 = make_plot(linear_cmap, \"Viridis256\")\n",
    "p2 = make_plot(log_cmap, \"Viridis256\")\n",
    "p3 = make_plot(linear_cmap, \"Viridis6\")\n",
    "p4 = make_plot(log_cmap, \"Viridis6\")\n",
    "\n",
    "p5 = figure(x_range=(1, 1000), width=800, height=300, toolbar_location=None, tools=\"\",\n",
    "            title=\"Viridis256 with linear_cmap, low/high = 200/800 = pink/grey\")\n",
    "cmap = linear_cmap(\"x\", palette=\"Viridis256\", low=200, high=800,\n",
    "                   low_color=\"pink\", high_color=\"darkgrey\")\n",
    "p5.scatter(x='x', y='y', alpha=0.8, source=source, color=cmap)\n",
    "\n",
    "grid =  gridplot([[p1, p2], [p3, p4]], width=400, height=300, toolbar_location=None)\n",
    "show(column(grid, p5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e3c5fa-eeba-41ac-9b09-6ef828d01491",
   "metadata": {},
   "source": [
    "## Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f34db28-7e9a-4f9c-9d37-b41362e60f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "\n",
    "df = dask.datasets.timeseries(freq='1d')\n",
    "df.dtypes\n",
    "%matplotlib inline\n",
    "df[['x', 'y']].resample('24h').mean().compute().plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd38b96-f463-4486-9433-dd129038738d",
   "metadata": {},
   "source": [
    "## Juliet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37f6c90-0cc4-4ab5-a841-c8bba8c00062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import juliet\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# First, get arrays of times, normalized-fluxes and errors for HATS-46\n",
    "# from Sector 1 from MAST:\n",
    "t,f,ferr  = juliet.get_TESS_data('https://archive.stsci.edu/hlsps/tess-data-alerts/'+\\\n",
    "                                 'hlsp_tess-data-alerts_tess_phot_00403224672-'+\\\n",
    "                                 's01_tess_v1_lc.fits')\n",
    "\n",
    "# Create dictionaries:\n",
    "times, fluxes, fluxes_error = {},{},{}\n",
    "# Save data into those dictionaries:\n",
    "times['TESS'], fluxes['TESS'], fluxes_error['TESS'] = t,f,ferr\n",
    "\n",
    "\n",
    "priors = {}\n",
    "\n",
    "# Name of the parameters to be fit:\n",
    "params = ['P_p1','t0_p1','r1_p1','r2_p1','q1_TESS','q2_TESS','ecc_p1','omega_p1',\\\n",
    "              'rho', 'mdilution_TESS', 'mflux_TESS', 'sigma_w_TESS']\n",
    "\n",
    "# Distribution for each of the parameters:\n",
    "dists = ['normal','normal','uniform','uniform','uniform','uniform','fixed','fixed',\\\n",
    "                 'loguniform', 'fixed', 'normal', 'loguniform']\n",
    "\n",
    "# Hyperparameters of the distributions (mean and standard-deviation for normal\n",
    "# distributions, lower and upper limits for uniform and loguniform distributions, and\n",
    "# fixed values for fixed \"distributions\", which assume the parameter is fixed)\n",
    "hyperps = [[1.,0.1], [1325.55,0.1], [0.,1], [0.,1.], [0., 1.], [0., 1.], 0.0, 90.,\\\n",
    "                   [100., 10000.], 1.0, [0.,0.1], [0.1, 1000.]]\n",
    "\n",
    "# Populate the priors dictionary:\n",
    "for param, dist, hyperp in zip(params, dists, hyperps):\n",
    "    priors[param] = {}\n",
    "    priors[param]['distribution'], priors[param]['hyperparameters'] = dist, hyperp\n",
    "\n",
    "# Load dataset into juliet, save results to a temporary folder called toi141_fit:\n",
    "dataset = juliet.load(priors=priors, t_lc = times, y_lc = fluxes, \\\n",
    "                      yerr_lc = fluxes_error, out_folder = 'toi141_fit')\n",
    "\n",
    "# Fit and absorb results into a juliet.fit object:\n",
    "# SHOULD TAKE ~10 seconds\n",
    "results = dataset.fit(n_live_points = 10, nwalkers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f89e647-01d6-4fe5-8626-f6fec34d3936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: no zeus installation found. Will not be able to sample using sampler = 'zeus'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mjuliet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpriors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstarting_point\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minput_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mt_lc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0my_lc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0myerr_lc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mt_rv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0my_rv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0myerr_rv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mGP_regressors_lc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlinear_regressors_lc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mGP_regressors_rv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlinear_regressors_rv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mout_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlcfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrvfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mGPlceparamfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mGPrveparamfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mLMlceparamfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mLMrveparamfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlctimedef\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'TDB'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrvtimedef\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'UTC'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mld_laws\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'quadratic'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpriorfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlc_n_supersamp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlc_exptime_supersamp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlc_instrument_supersamp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmag_to_flux\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmatern_eps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgeorge_hodlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpickle_encoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Given a dictionary with priors (or a filename pointing to a prior file) and data either given through arrays\n",
       "or through files containing the data, this class loads data into a juliet object which holds all the information\n",
       "about the dataset. Example usage:\n",
       "\n",
       "           >>> data = juliet.load(priors=priors,t_lc=times,y_lc=fluxes,yerr_lc=fluxes_errors)\n",
       "\n",
       "Or, also,\n",
       "\n",
       "           >>> data = juliet.load(input_folder = folder)\n",
       "\n",
       ":param priors: (optional, dict or string)\n",
       "    This can be either a python ``string`` or a python ``dict``. If a ``dict``, this has to contain each of\n",
       "    the parameters to be fit, along with their respective prior distributions and hyperparameters. Each key\n",
       "    of this dictionary has to have a parameter name (e.g., ``r1_p1``, ``sigma_w_TESS``), and each of\n",
       "    those elements are, in turn, dictionaries as well containing two keys: a ``distribution``\n",
       "    key which defines the prior distribution of the parameter and a ``hyperparameters`` key,\n",
       "    which contains the hyperparameters of that distribution.\n",
       "\n",
       "    Example setup of the ``priors`` dictionary:\n",
       "        >>> priors = {}\n",
       "        >>> priors['r1_p1'] = {}\n",
       "        >>> priors['r1_p1']['distribution'] = 'Uniform'\n",
       "        >>> priors['r1_p1']['hyperparameters'] = [0.,1.]\n",
       "\n",
       "    If a ``string``, this has to contain the filename to a proper juliet prior file; the prior ``dict`` will\n",
       "    then be generated from there. A proper prior file has in the first column the name of the parameter,\n",
       "    in the second the name of the distribution, and in the third the hyperparameters of that distribution for\n",
       "    the parameter.\n",
       "\n",
       "    Note that this along with either lightcurve or RV data or a ``input_folder`` has to be given in order to properly\n",
       "    load a juliet data object.\n",
       "\n",
       ":param starting_point: (mandatory if using MCMC, useless if using nested samplers, dict)\n",
       "    Dictionary indicating the starting value of each of the parameters for the MCMC run (i.e., currently only of use for ``emcee``). Keys should be consistent with the ``prior`` namings above;\n",
       "    each key should have an associated float with the starting value. This is of no use if using nested samplers (which sample directly from the prior).\n",
       "\n",
       ":param input_folder: (optional, string)\n",
       "    Python ``string`` containing the path to a folder containing all the input data --- this will thus be load into a\n",
       "    juliet data object. This input folder has to contain at least a ``priors.dat`` file with the priors and either a ``lc.dat``\n",
       "    file containing lightcurve data or a ``rvs.dat`` file containing radial-velocity data. If in this folder a ``GP_lc_regressors.dat``\n",
       "    file or a ``GP_rv_regressors.dat`` file is found, data will be loaded into the juliet object as well.\n",
       "\n",
       "    Note that at least this or a ``priors`` string or dictionary, along with either lightcurve or RV data has to be given\n",
       "    in order to properly load a juliet data object.\n",
       "\n",
       ":param t_lc: (optional, dictionary)\n",
       "    Dictionary whose keys are instrument names; each of those keys is expected to have arrays with the times corresponding to those instruments.\n",
       "    For example,\n",
       "                                >>> t_lc = {}\n",
       "                                >>> t_lc['TESS'] = np.linspace(0,100,100)\n",
       "\n",
       "    Is a valid input dictionary for ``t_lc``.\n",
       "\n",
       ":param y_lc: (optional, dictionary)\n",
       "    Similarly to ``t_lc``, dictionary whose keys are instrument names; each of those keys is expected to have arrays with the fluxes corresponding to those instruments.\n",
       "    These are expected to be consistent with the ``t_lc`` dictionaries.\n",
       "\n",
       ":param yerr_lc: (optional, dictionary)\n",
       "    Similarly to ``t_lc``, dictionary whose keys are instrument names; each of those keys is expected to have arrays with the errors on the fluxes corresponding to those instruments.\n",
       "    These are expected to be consistent with the ``t_lc`` dictionaries.\n",
       "\n",
       ":param GP_regressors_lc: (optional, dictionary)\n",
       "    Dictionary whose keys are names of instruments where a GP is to be fit. On each name/element, an array of\n",
       "    regressors of shape ``(m,n)`` containing in each column the ``n`` GP regressors to be used for\n",
       "    ``m`` photometric measurements has to be given. Note that ``m`` for a given instrument has to be of the same length\n",
       "    as the corresponding ``t_lc`` for that instrument. Also, note the order of each regressor of each instrument has to match\n",
       "    the corresponding order in the ``t_lc`` array.\n",
       "    For example,\n",
       "\n",
       "                                >>> GP_regressors_lc = {}\n",
       "                                >>> GP_regressors_lc['TESS'] = np.linspace(-1,1,100)\n",
       "\n",
       "    If a global model wants to be used, then the instrument should be ``rv``, and each of the ``m`` rows should correspond to the ``m`` times.\n",
       "\n",
       ":param linear_regressors_lc: (optional, dictionary)\n",
       "    Similarly as for ``GP_regressors_lc``, this is a dictionary whose keys are names of instruments where a linear regression is to be fit.\n",
       "    On each name/element, an array of shape ``(q,p)`` containing in each column the ``p`` linear regressors to be used for the ``q``\n",
       "    photometric measurements. Again, note the order of each regressor of each instrument has to match the corresponding order in the ``t_lc`` array.\n",
       "\n",
       ":param GP_regressors_rv: (optional, dictionary)\n",
       "    Same as ``GP_regressors_lc`` but for the radial-velocity data. If a global model wants to be used, then the instrument should be ``lc``, and each of the ``m`` rows should correspond to the ``m`` times.\n",
       "\n",
       ":param linear_regressors_rv: (optional, dictionary)\n",
       "    Same as ``linear_regressors_lc``, but for the radial-velocities.\n",
       "\n",
       ":param t_rv: (optional, dictionary)\n",
       "    Same as ``t_lc``, but for the radial-velocities.\n",
       "\n",
       ":param y_rv: (optional, dictionary)\n",
       "    Same as ``y_lc``, but for the radial-velocities.\n",
       "\n",
       ":param yerr_rv: (optional, dictionary)\n",
       "    Same as ``yerr_lc``, but for the radial-velocities.\n",
       "\n",
       ":param out_folder: (optional, string)\n",
       "    If a path is given, results will be saved to that path as a ``pickle`` file, along with all inputs in the standard juliet format.\n",
       "\n",
       ":param lcfilename:  (optional, string)\n",
       "    If a path to a lightcurve file is given, ``t_lc``, ``y_lc``, ``yerr_lc`` and ``instruments_lc`` will be read from there. The basic file format is a pure\n",
       "    ascii file where times are in the first column, relative fluxes in the second, errors in the third and instrument names in the fourth. If more columns are given for\n",
       "    a given instrument, those will be identified as linear regressors for those instruments.\n",
       "\n",
       ":param rvfilename: (optional, string)\n",
       "    Same as ``lcfilename``, but for the radial-velocities.\n",
       "\n",
       ":param GPlceparamfile: (optional, string)\n",
       "    If a path to a file is given, the columns of that file will be used as GP regressors for the lightcurve fit. The file format is a pure ascii file\n",
       "    where regressors are given in different columns, and the last column holds the instrument name. The order of this file has to be consistent with\n",
       "    ``t_lc`` and/or the ``lcfilename`` file. If a global model wants to be used, set the instrument names of all regressors to ``lc``.\n",
       "\n",
       ":param GPrveparamfile: (optional, string)\n",
       "    Same as ``GPlceparamfile`` but for the radial-velocities. If a global model wants to be used, set the instrument names of all regressors to ``rv``.\n",
       "\n",
       ":param LMlceparamfile: (optional, string)\n",
       "    If a path to a file is given, the columns of that file will be used as linear regressors for the lightcurve fit. The file format is a pure ascii file\n",
       "    where regressors are given in different columns, and the last column holds the instrument name. The order of this file has to be consistent with\n",
       "    ``t_lc`` and/or the ``lcfilename`` file. If a global model wants to be used, set the instrument names of all regressors to ``lc``.\n",
       "\n",
       ":param LMrveparamfile: (optional, string)\n",
       "    Same as ``LMlceparamfile`` but for the radial-velocities. If a global model wants to be used, set the instrument names of all regressors to ``rv``.\n",
       "\n",
       ":param lctimedef: (optional, string)\n",
       "    Time definitions for each of the lightcurve instruments. Default is to assume all instruments (in lcs and rvs) have the same time definitions. If more than one instrument is given, this string\n",
       "    should have instruments and time-definitions separated by commas, e.g., ``TESS-TDB, LCOGT-UTC``, etc.\n",
       "\n",
       ":param rvtimedef: (optional, string)\n",
       "    Time definitions for each of the radial-velocity instruments. Default is to assume all instruments (in lcs and rvs) have the same time definitions. If more than one instrument is given,\n",
       "    this string should have instruments and time-definitions separated by commas, e.g., ``FEROS-TDB, HARPS-UTC``, etc.\n",
       "\n",
       ":param ld_laws: (optional, string)\n",
       "    Limb-darkening law to be used for each instrument. Default is ``quadratic`` for all instruments. If more than one instrument is given,\n",
       "    this string should have instruments and limb-darkening laws separated by commas, e.g., ``TESS-quadratic, LCOGT-linear``.\n",
       "\n",
       ":param priorfile: (optional, string)\n",
       "    If a path to a file is given, it will be assumed this is a prior file. The ``priors`` dictionary will be overwritten by the data in this\n",
       "    file. The file structure is a plain ascii file, with the name of the parameters in the first column, name of the prior distribution in the\n",
       "    second column and hyperparameters in the third column.\n",
       "\n",
       ":param lc_instrument_supersamp: (optional, array of strings)\n",
       "    Define for which lightcurve instruments super-sampling will be applied (e.g., in the case of long-cadence integrations). e.g., ``lc_instrument_supersamp = ['TESS','K2']``\n",
       "\n",
       ":param lc_n_supersamp: (optional, array of ints)\n",
       "    Define the number of datapoints to supersample. Order should be consistent with order in ``lc_instrument_supersamp``. e.g., ``lc_n_supersamp = [20,30]``.\n",
       "\n",
       ":param lc_exptime_supersamp: (optional, array of floats)\n",
       "    Define the exposure-time of the observations for the supersampling. Order should be consistent with order in ``lc_instrument_supersamp``. e.g., ``lc_exptime_supersamp = [0.020434,0.020434]``\n",
       "\n",
       ":param verbose: (optional, boolean)\n",
       "    If True, all outputs of the code are printed to terminal. Default is False.\n",
       "\n",
       ":param matern_eps: (optional, float)\n",
       "    Epsilon parameter for the Matern approximation (see celerite documentation).\n",
       "\n",
       ":param george_hodlr: (optional, bool)\n",
       "    Flag to define if you want to use the HODLR solver for george GP's or not (see http://dfm.io/george/current/user/solvers/).\n",
       "\n",
       ":param pickle_encoding: (optional, string)\n",
       "    Define pickle encoding in case fit was done with Python 2.7 and results are read with Python 3.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/miniconda3/envs/tike-test/lib/python3.11/site-packages/juliet/fit.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import juliet\n",
    "juliet.load?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b75741-35cc-44ac-9c1f-3f0eb15718e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import juliet\n",
    "priors = {}\n",
    "\n",
    "# Name of the parameters to be fit:\n",
    "params = ['P_p1','t0_p1','mu_CORALIE14', \\\n",
    "          'mu_CORALIE07','mu_HARPS','mu_FEROS',\\\n",
    "          'K_p1', 'ecc_p1', 'omega_p1', 'sigma_w_CORALIE14','sigma_w_CORALIE07',\\\n",
    "           'sigma_w_HARPS','sigma_w_FEROS']\n",
    "\n",
    "# Distributions:\n",
    "dists = ['normal','normal','uniform', \\\n",
    "         'uniform','uniform','uniform',\\\n",
    "         'uniform','fixed', 'fixed', 'loguniform', 'loguniform',\\\n",
    "         'loguniform', 'loguniform']\n",
    "\n",
    "# Hyperparameters\n",
    "hyperps = [[1.007917,0.000073], [2458325.5386,0.0011], [-100,100], \\\n",
    "           [-100,100], [-100,100], [-100,100], \\\n",
    "           [0.,100.], 0., 90., [1e-3, 100.], [1e-3, 100.], \\\n",
    "           [1e-3, 100.], [1e-3, 100.]]\n",
    "\n",
    "# Populate the priors dictionary:\n",
    "for param, dist, hyperp in zip(params, dists, hyperps):\n",
    "    priors[param] = {}\n",
    "    priors[param]['distribution'], priors[param]['hyperparameters'] = dist, hyperp\n",
    "\n",
    "dataset = juliet.load(priors = priors, rvfilename='rvs_toi141.dat', out_folder = 'toi141_rvs')\n",
    "results = dataset.fit(n_live_points = 10, nwalkers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f74e861-0f05-407d-9c56-a224ada4b802",
   "metadata": {},
   "source": [
    "## Lightkurve\n",
    "\n",
    "These tests will take about 30 seconds to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ff972b-bf33-4633-ad13-c55d5dd7468d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightkurve as lk\n",
    "%matplotlib inline\n",
    "lc = lk.search_lightcurve('KIC 6185476', author='Kepler', cadence='long').download_all().stitch()\n",
    "lc.plot();\n",
    "\n",
    "clc = lc.flatten(21)\n",
    "clc.plot();\n",
    "\n",
    "p, t0 = 17.660114, 136.57258\n",
    "folded_lc = clc.fold(period=p, epoch_time=t0)\n",
    "folded_lc.scatter();\n",
    "\n",
    "folded_lc.plot_river(bin_points=1, method='sigma');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaa205d-5270-448c-9da8-c45aee934bf7",
   "metadata": {},
   "source": [
    "## Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e739b219-5ba9-44e6-bb36-843fca667903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.cluster import SpectralCoclustering\n",
    "from sklearn.datasets import make_biclusters\n",
    "from sklearn.metrics import consensus_score\n",
    "\n",
    "data, rows, columns = make_biclusters(\n",
    "    shape=(300, 300), n_clusters=5, noise=5, shuffle=False, random_state=0\n",
    ")\n",
    "\n",
    "plt.matshow(data, cmap=plt.cm.Blues)\n",
    "plt.title(\"Original dataset\")\n",
    "\n",
    "# shuffle clusters\n",
    "rng = np.random.RandomState(0)\n",
    "row_idx = rng.permutation(data.shape[0])\n",
    "col_idx = rng.permutation(data.shape[1])\n",
    "data = data[row_idx][:, col_idx]\n",
    "\n",
    "plt.matshow(data, cmap=plt.cm.Blues)\n",
    "plt.title(\"Shuffled dataset\")\n",
    "\n",
    "model = SpectralCoclustering(n_clusters=5, random_state=0)\n",
    "model.fit(data)\n",
    "score = consensus_score(model.biclusters_, (rows[:, row_idx], columns[:, col_idx]))\n",
    "\n",
    "print(\"consensus score: {:.3f}\".format(score))\n",
    "\n",
    "fit_data = data[np.argsort(model.row_labels_)]\n",
    "fit_data = fit_data[:, np.argsort(model.column_labels_)]\n",
    "\n",
    "plt.matshow(fit_data, cmap=plt.cm.Blues)\n",
    "plt.title(\"After biclustering; rearranged to show biclusters\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db05fa8-f59e-4bea-a682-e25a469c3e88",
   "metadata": {},
   "source": [
    "## Scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69207e2-ff07-44c7-bfc2-65f69a688fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp2d, RectBivariateSpline\n",
    "\n",
    "x = np.arange(-5.01, 5.01, 0.25)\n",
    "y = np.arange(-5.01, 7.51, 0.25)\n",
    "xx, yy = np.meshgrid(x, y)\n",
    "z = np.sin(xx**2 + 2.*yy**2)\n",
    "f = interp2d(x, y, z, kind='cubic')\n",
    "\n",
    "def plot(f, xnew, ynew):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\n",
    "    znew = f(xnew, ynew)\n",
    "\n",
    "    ax1.plot(x, z[0, :], 'ro-', xnew, znew[0, :], 'b-')\n",
    "\n",
    "    im = ax2.imshow(znew)\n",
    "    plt.colorbar(im, ax=ax2)\n",
    "\n",
    "    plt.show()\n",
    "    return znew\n",
    "\n",
    "xnew = np.arange(-5.01, 5.01, 1e-2)\n",
    "ynew = np.arange(-5.01, 7.51, 1e-2)\n",
    "znew_i = plot(f, xnew, ynew)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d7f72e-e196-4c82-b1f9-168f276947ed",
   "metadata": {},
   "source": [
    "## TESS_Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f9961c-52bb-4e98-9ffb-6466cf954623",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tess_stars2px import tess_stars2px_function_entry\n",
    "\n",
    "ra = 84.291188 \n",
    "dec = -80.469119\n",
    "ticid = 261136679\n",
    "\n",
    "outID, outEclipLong, outEclipLat, outSec, outCam, outCcd, \\\n",
    "        outColPix, outRowPix, scinfo = tess_stars2px_function_entry(\n",
    "                ticid, ra, dec)\n",
    "for i in range(len(outID)):\n",
    "    print('{0:d} {1:d} {2:d} {3:d} {4:f} {5:f}'.format(outID[i], outSec[i], \\\n",
    "      outCam[i], outCcd[i], outColPix[i], outRowPix[i]))\n",
    "    \n",
    "# For efficiency purposes if you save scinfo between calls\n",
    "#  you will save time in setting up the the telescope fields\n",
    "outID, outEclipLong, outEclipLat, outSec, outCam, outCcd, \\\n",
    "        outColPix, outRowPix, scinfo = tess_stars2px_function_entry(\n",
    "                ticid, ra, dec, scInfo=scinfo)\n",
    "print('Faster to re-use scinfo in repeated calls')\n",
    "for i in range(len(outID)):\n",
    "    print('{0:d} {1:d} {2:d} {3:d} {4:f} {5:f}'.format(outID[i], outSec[i], \\\n",
    "      outCam[i], outCcd[i], outColPix[i], outRowPix[i]))\n",
    "\n",
    "print('Also accepts multiple targets')\n",
    "ra = np.array([219.90085,10.897379])\n",
    "dec = np.array([-60.835619,-17.986606])\n",
    "ticid = np.array([0,1])\n",
    "outID, outEclipLong, outEclipLat, outSec, outCam, outCcd, \\\n",
    "        outColPix, outRowPix, scinfo = tess_stars2px_function_entry(\n",
    "                ticid, ra, dec, scInfo=scinfo)\n",
    "for i in range(len(outID)):\n",
    "    print('{0:d} {1:d} {2:d} {3:d} {4:f} {5:f}'.format(outID[i], outSec[i], \\\n",
    "          outCam[i], outCcd[i], outColPix[i], outRowPix[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a690565c-d461-4177-9fd3-40a82b607315",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc646f1d-c043-48e3-b821-02eb4b23b29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"Name\": [\n",
    "            \"Braund, Mr. Owen Harris\",\n",
    "            \"Allen, Mr. William Henry\",\n",
    "            \"Bonnell, Miss. Elizabeth\",\n",
    "        ],\n",
    "        \"Age\": [22, 35, 58],\n",
    "        \"Sex\": [\"male\", \"male\", \"female\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "df[\"Age\"].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aba872c-a954-434f-85b1-7468914ce6ae",
   "metadata": {},
   "source": [
    "## Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb51ff1-18cf-41bb-ac1f-5d324ac4c746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.get('https://httpbin.org/basic-auth/user/pass', auth=('user', 'pass'))\n",
    "print(r.status_code, r.headers['content-type'], r.encoding, r.text, r.json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
